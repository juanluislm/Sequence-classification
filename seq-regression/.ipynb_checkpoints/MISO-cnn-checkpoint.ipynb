{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[207.56213]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    " \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "# one time series per head\n",
    "n_features = 1\n",
    "# separate input data\n",
    "X1 = X[:, :, 0].reshape(X.shape[0], X.shape[1], n_features)\n",
    "X2 = X[:, :, 1].reshape(X.shape[0], X.shape[1], n_features)\n",
    "# first input model\n",
    "visible1 = Input(shape=(n_steps, n_features))\n",
    "cnn1 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible1)\n",
    "cnn1 = MaxPooling1D(pool_size=2)(cnn1)\n",
    "cnn1 = Flatten()(cnn1)\n",
    "# second input model\n",
    "visible2 = Input(shape=(n_steps, n_features))\n",
    "cnn2 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible2)\n",
    "cnn2 = MaxPooling1D(pool_size=2)(cnn2)\n",
    "cnn2 = Flatten()(cnn2)\n",
    "# merge input models\n",
    "merge = concatenate([cnn1, cnn2])\n",
    "dense = Dense(50, activation='relu')(merge)\n",
    "output = Dense(1)(dense)\n",
    "model = Model(inputs=[visible1, visible2], outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit([X1, X2], y, epochs=1000, verbose=0)\n",
    "# demonstrate prediction\n",
    "x_input = array([[80, 85], [90, 95], [100, 105]])\n",
    "x1 = x_input[:, 0].reshape((1, n_steps, n_features))\n",
    "x2 = x_input[:, 1].reshape((1, n_steps, n_features))\n",
    "yhat = model.predict([x1, x2], verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
