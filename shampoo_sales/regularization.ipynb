{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Test RMSE: 103.801\n",
      "2) Test RMSE: 102.154\n",
      "3) Test RMSE: 97.784\n",
      "4) Test RMSE: 97.424\n",
      "5) Test RMSE: 96.103\n",
      "6) Test RMSE: 101.939\n",
      "7) Test RMSE: 107.642\n",
      "8) Test RMSE: 105.947\n",
      "9) Test RMSE: 100.953\n",
      "10) Test RMSE: 98.215\n",
      "11) Test RMSE: 100.214\n",
      "12) Test RMSE: 105.046\n",
      "13) Test RMSE: 98.000\n",
      "14) Test RMSE: 104.419\n",
      "15) Test RMSE: 91.081\n",
      "16) Test RMSE: 104.118\n",
      "17) Test RMSE: 89.037\n",
      "18) Test RMSE: 105.725\n",
      "19) Test RMSE: 101.077\n",
      "20) Test RMSE: 100.474\n",
      "21) Test RMSE: 100.627\n",
      "22) Test RMSE: 103.769\n",
      "23) Test RMSE: 100.732\n",
      "24) Test RMSE: 105.169\n",
      "25) Test RMSE: 99.386\n",
      "26) Test RMSE: 90.229\n",
      "27) Test RMSE: 90.224\n",
      "28) Test RMSE: 93.399\n",
      "29) Test RMSE: 106.395\n",
      "30) Test RMSE: 94.516\n",
      "          results\n",
      "count   30.000000\n",
      "mean    99.853247\n",
      "std      5.234192\n",
      "min     89.036614\n",
      "25%     97.514189\n",
      "50%    100.679157\n",
      "75%    104.038815\n",
      "max    107.641611\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.regularizers import L1L2\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "# be able to save images on server\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    " \n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    " \n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\treturn df\n",
    " \n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    " \n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    " \n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    " \n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, yhat):\n",
    "\tnew_row = [x for x in X] + [yhat]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    " \n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, n_batch, nb_epoch, n_neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    " \n",
    "# run a repeated experiment\n",
    "def experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons):\n",
    "\t# transform data to be stationary\n",
    "\traw_values = series.values\n",
    "\tdiff_values = difference(raw_values, 1)\n",
    "\t# transform data to be supervised learning\n",
    "\tsupervised = timeseries_to_supervised(diff_values, n_lag)\n",
    "\tsupervised_values = supervised.values[n_lag:,:]\n",
    "\t# split data into train and test-sets\n",
    "\ttrain, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\t# run experiment\n",
    "\terror_scores = list()\n",
    "\tfor r in range(n_repeats):\n",
    "\t\t# fit the model\n",
    "\t\ttrain_trimmed = train_scaled[2:, :]\n",
    "\t\tlstm_model = fit_lstm(train_trimmed, n_batch, n_epochs, n_neurons)\n",
    "\t\t# forecast test dataset\n",
    "\t\ttest_reshaped = test_scaled[:,0:-1]\n",
    "\t\ttest_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "\t\toutput = lstm_model.predict(test_reshaped, batch_size=n_batch)\n",
    "\t\tpredictions = list()\n",
    "\t\tfor i in range(len(output)):\n",
    "\t\t\tyhat = output[i,0]\n",
    "\t\t\tX = test_scaled[i, 0:-1]\n",
    "\t\t\t# invert scaling\n",
    "\t\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t\t# invert differencing\n",
    "\t\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t\t# store forecast\n",
    "\t\t\tpredictions.append(yhat)\n",
    "\t\t# report performance\n",
    "\t\trmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "\t\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "\t\terror_scores.append(rmse)\n",
    "\treturn error_scores\n",
    " \n",
    "# configure the experiment\n",
    "def run():\n",
    "\t# load dataset\n",
    "\tseries = read_csv('sales-of-shampoo-over-a-three-ye.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "\t# configure the experiment\n",
    "\tn_lag = 1\n",
    "\tn_repeats = 30\n",
    "\tn_epochs = 1000\n",
    "\tn_batch = 4\n",
    "\tn_neurons = 3\n",
    "\t# run the experiment\n",
    "\tresults = DataFrame()\n",
    "\tresults['results'] = experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons)\n",
    "\t# summarize results\n",
    "\tprint(results.describe())\n",
    "\t# save boxplot\n",
    "\tresults.boxplot()\n",
    "\tpyplot.savefig('experiment_baseline.png')\n",
    " \n",
    "# entry point\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Test RMSE: 102.756\n",
      "2) Test RMSE: 103.659\n",
      "3) Test RMSE: 101.663\n",
      "4) Test RMSE: 96.790\n",
      "5) Test RMSE: 90.144\n",
      "6) Test RMSE: 98.907\n",
      "7) Test RMSE: 103.628\n",
      "8) Test RMSE: 99.703\n",
      "9) Test RMSE: 95.826\n",
      "10) Test RMSE: 100.191\n",
      "11) Test RMSE: 96.548\n",
      "12) Test RMSE: 91.192\n",
      "13) Test RMSE: 95.299\n",
      "14) Test RMSE: 93.010\n",
      "15) Test RMSE: 102.276\n",
      "16) Test RMSE: 90.415\n",
      "17) Test RMSE: 109.124\n",
      "18) Test RMSE: 99.815\n",
      "19) Test RMSE: 92.226\n",
      "20) Test RMSE: 96.549\n",
      "21) Test RMSE: 97.072\n",
      "22) Test RMSE: 101.863\n",
      "23) Test RMSE: 97.426\n",
      "24) Test RMSE: 93.314\n",
      "25) Test RMSE: 102.036\n",
      "26) Test RMSE: 100.225\n",
      "27) Test RMSE: 100.881\n",
      "28) Test RMSE: 86.669\n",
      "29) Test RMSE: 98.511\n",
      "30) Test RMSE: 96.206\n",
      "1) Test RMSE: 98.494\n",
      "2) Test RMSE: 97.998\n",
      "3) Test RMSE: 100.179\n",
      "4) Test RMSE: 107.570\n",
      "5) Test RMSE: 100.809\n",
      "6) Test RMSE: 96.645\n",
      "7) Test RMSE: 93.153\n",
      "8) Test RMSE: 99.547\n",
      "9) Test RMSE: 112.056\n",
      "10) Test RMSE: 110.923\n",
      "11) Test RMSE: 104.424\n",
      "12) Test RMSE: 103.315\n",
      "13) Test RMSE: 100.688\n",
      "14) Test RMSE: 95.311\n",
      "15) Test RMSE: 103.196\n",
      "16) Test RMSE: 101.657\n",
      "17) Test RMSE: 96.661\n",
      "18) Test RMSE: 107.422\n",
      "19) Test RMSE: 106.247\n",
      "20) Test RMSE: 102.102\n",
      "21) Test RMSE: 95.502\n",
      "22) Test RMSE: 107.448\n",
      "23) Test RMSE: 106.202\n",
      "24) Test RMSE: 99.868\n",
      "25) Test RMSE: 102.666\n",
      "26) Test RMSE: 104.648\n",
      "27) Test RMSE: 108.051\n",
      "28) Test RMSE: 107.898\n",
      "29) Test RMSE: 96.193\n",
      "30) Test RMSE: 97.213\n",
      "1) Test RMSE: 98.115\n",
      "2) Test RMSE: 106.792\n",
      "3) Test RMSE: 96.867\n",
      "4) Test RMSE: 101.008\n",
      "5) Test RMSE: 108.347\n",
      "6) Test RMSE: 99.143\n",
      "7) Test RMSE: 97.463\n",
      "8) Test RMSE: 96.839\n",
      "9) Test RMSE: 98.603\n",
      "10) Test RMSE: 105.694\n",
      "11) Test RMSE: 96.310\n",
      "12) Test RMSE: 101.658\n",
      "13) Test RMSE: 101.797\n",
      "14) Test RMSE: 104.152\n",
      "15) Test RMSE: 99.962\n",
      "16) Test RMSE: 100.262\n",
      "17) Test RMSE: 99.777\n",
      "18) Test RMSE: 96.366\n",
      "19) Test RMSE: 101.029\n",
      "20) Test RMSE: 104.078\n",
      "21) Test RMSE: 101.497\n",
      "22) Test RMSE: 97.158\n",
      "23) Test RMSE: 109.377\n",
      "24) Test RMSE: 102.901\n",
      "25) Test RMSE: 105.963\n",
      "26) Test RMSE: 102.152\n",
      "27) Test RMSE: 100.141\n",
      "28) Test RMSE: 108.847\n",
      "29) Test RMSE: 111.169\n",
      "30) Test RMSE: 109.078\n",
      "1) Test RMSE: 108.222\n",
      "2) Test RMSE: 99.653\n",
      "3) Test RMSE: 95.270\n",
      "4) Test RMSE: 106.311\n",
      "5) Test RMSE: 104.097\n",
      "6) Test RMSE: 107.058\n",
      "7) Test RMSE: 105.400\n",
      "8) Test RMSE: 103.799\n",
      "9) Test RMSE: 100.155\n",
      "10) Test RMSE: 110.929\n",
      "11) Test RMSE: 109.402\n",
      "12) Test RMSE: 108.018\n",
      "13) Test RMSE: 100.410\n",
      "14) Test RMSE: 95.880\n",
      "15) Test RMSE: 100.645\n",
      "16) Test RMSE: 104.323\n",
      "17) Test RMSE: 102.449\n",
      "18) Test RMSE: 110.021\n",
      "19) Test RMSE: 107.871\n",
      "20) Test RMSE: 102.879\n",
      "21) Test RMSE: 95.159\n",
      "22) Test RMSE: 109.862\n",
      "23) Test RMSE: 106.037\n",
      "24) Test RMSE: 99.669\n",
      "25) Test RMSE: 96.882\n",
      "26) Test RMSE: 98.524\n",
      "27) Test RMSE: 93.817\n",
      "28) Test RMSE: 93.744\n",
      "29) Test RMSE: 105.348\n",
      "30) Test RMSE: 91.956\n",
      "       l1 0.00,l2 0.00  l1 0.01,l2 0.00  l1 0.00,l2 0.01  l1 0.01,l2 0.01\n",
      "count        30.000000        30.000000        30.000000        30.000000\n",
      "mean         97.797423       102.136242       102.084850       102.459689\n",
      "std           4.889678         4.977221         4.360848         5.519517\n",
      "min          86.669038        93.152744        96.309793        91.956039\n",
      "25%          95.430454        98.121807        98.737762        98.806237\n",
      "50%          97.968579       101.879750       101.263086       103.338916\n",
      "75%         101.467326       106.235761       105.308290       106.871255\n",
      "max         109.123672       112.056174       111.169460       110.928983\n"
     ]
    }
   ],
   "source": [
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, n_batch, nb_epoch, n_neurons, reg):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True, bias_regularizer=reg))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    " \n",
    "# run a repeated experiment\n",
    "def experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons, reg):\n",
    "\t# transform data to be stationary\n",
    "\traw_values = series.values\n",
    "\tdiff_values = difference(raw_values, 1)\n",
    "\t# transform data to be supervised learning\n",
    "\tsupervised = timeseries_to_supervised(diff_values, n_lag)\n",
    "\tsupervised_values = supervised.values[n_lag:,:]\n",
    "\t# split data into train and test-sets\n",
    "\ttrain, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\t# transform the scale of the data\n",
    "\tscaler, train_scaled, test_scaled = scale(train, test)\n",
    "\t# run experiment\n",
    "\terror_scores = list()\n",
    "\tfor r in range(n_repeats):\n",
    "\t\t# fit the model\n",
    "\t\ttrain_trimmed = train_scaled[2:, :]\n",
    "\t\tlstm_model = fit_lstm(train_trimmed, n_batch, n_epochs, n_neurons, reg)\n",
    "\t\t# forecast test dataset\n",
    "\t\ttest_reshaped = test_scaled[:,0:-1]\n",
    "\t\ttest_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "\t\toutput = lstm_model.predict(test_reshaped, batch_size=n_batch)\n",
    "\t\tpredictions = list()\n",
    "\t\tfor i in range(len(output)):\n",
    "\t\t\tyhat = output[i,0]\n",
    "\t\t\tX = test_scaled[i, 0:-1]\n",
    "\t\t\t# invert scaling\n",
    "\t\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\t\t# invert differencing\n",
    "\t\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\t\t# store forecast\n",
    "\t\t\tpredictions.append(yhat)\n",
    "\t\t# report performance\n",
    "\t\trmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "\t\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "\t\terror_scores.append(rmse)\n",
    "\treturn error_scores\n",
    " \n",
    "# configure the experiment\n",
    "# def run():\n",
    "# load dataset\n",
    "series = read_csv('sales-of-shampoo-over-a-three-ye.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# configure the experiment\n",
    "n_lag = 1\n",
    "n_repeats = 30\n",
    "n_epochs = 1000\n",
    "n_batch = 4\n",
    "n_neurons = 3\n",
    "regularizers = [L1L2(l1=0.0, l2=0.0), L1L2(l1=0.01, l2=0.0), L1L2(l1=0.0, l2=0.01), L1L2(l1=0.01, l2=0.01)]\n",
    "# run the experiment\n",
    "results = DataFrame()\n",
    "for reg in regularizers:\n",
    "    name = ('l1 %.2f,l2 %.2f' % (reg.l1, reg.l2))\n",
    "    results[name] = experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons, reg)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('experiment_reg_bias.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Test RMSE: 101.202\n",
      "2) Test RMSE: 90.671\n",
      "3) Test RMSE: 101.603\n",
      "4) Test RMSE: 102.153\n",
      "5) Test RMSE: 89.749\n",
      "6) Test RMSE: 98.850\n",
      "7) Test RMSE: 102.873\n",
      "8) Test RMSE: 94.765\n",
      "9) Test RMSE: 91.590\n",
      "10) Test RMSE: 89.169\n",
      "11) Test RMSE: 98.438\n",
      "12) Test RMSE: 102.296\n",
      "13) Test RMSE: 109.811\n",
      "14) Test RMSE: 97.078\n",
      "15) Test RMSE: 101.633\n",
      "16) Test RMSE: 94.771\n",
      "17) Test RMSE: 95.600\n",
      "18) Test RMSE: 90.956\n",
      "19) Test RMSE: 97.566\n",
      "20) Test RMSE: 99.801\n",
      "21) Test RMSE: 100.491\n",
      "22) Test RMSE: 93.169\n",
      "23) Test RMSE: 101.537\n",
      "24) Test RMSE: 96.519\n",
      "25) Test RMSE: 106.435\n",
      "26) Test RMSE: 104.144\n",
      "27) Test RMSE: 109.896\n",
      "28) Test RMSE: 105.345\n",
      "29) Test RMSE: 93.409\n",
      "30) Test RMSE: 92.402\n",
      "1) Test RMSE: 111.682\n",
      "2) Test RMSE: 119.877\n",
      "3) Test RMSE: 113.314\n",
      "4) Test RMSE: 102.117\n",
      "5) Test RMSE: 114.740\n",
      "6) Test RMSE: 108.843\n",
      "7) Test RMSE: 119.425\n",
      "8) Test RMSE: 121.916\n",
      "9) Test RMSE: 104.127\n",
      "10) Test RMSE: 105.037\n",
      "11) Test RMSE: 100.552\n",
      "12) Test RMSE: 107.203\n",
      "13) Test RMSE: 119.901\n",
      "14) Test RMSE: 121.888\n",
      "15) Test RMSE: 110.017\n",
      "16) Test RMSE: 110.826\n",
      "17) Test RMSE: 112.334\n",
      "18) Test RMSE: 99.463\n",
      "19) Test RMSE: 114.872\n",
      "20) Test RMSE: 114.169\n",
      "21) Test RMSE: 106.700\n",
      "22) Test RMSE: 117.028\n",
      "23) Test RMSE: 110.683\n",
      "24) Test RMSE: 110.312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b4dcf9f6bf73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'l1 %.2f,l2 %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b4dcf9f6bf73>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons, reg)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtrain_trimmed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trimmed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;31m# forecast test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtest_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b4dcf9f6bf73>\u001b[0m in \u001b[0;36mfit_lstm\u001b[0;34m(train, n_batch, nb_epoch, n_neurons, reg)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def fit_lstm(train, n_batch, nb_epoch, n_neurons, reg):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True, kernel_regularizer=reg))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    " \n",
    "# run a repeated experiment\n",
    "def experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons, reg):\n",
    "    # transform data to be stationary\n",
    "    raw_values = series.values\n",
    "    diff_values = difference(raw_values, 1)\n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised(diff_values, n_lag)\n",
    "    supervised_values = supervised.values[n_lag:,:]\n",
    "    # split data into train and test-sets\n",
    "    train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "    # run experiment\n",
    "    error_scores = list()\n",
    "    for r in range(n_repeats):\n",
    "        # fit the model\n",
    "        train_trimmed = train_scaled[2:, :]\n",
    "        lstm_model = fit_lstm(train_trimmed, n_batch, n_epochs, n_neurons, reg)\n",
    "        # forecast test dataset\n",
    "        test_reshaped = test_scaled[:,0:-1]\n",
    "        test_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "        output = lstm_model.predict(test_reshaped, batch_size=n_batch)\n",
    "        predictions = list()\n",
    "        for i in range(len(output)):\n",
    "            yhat = output[i,0]\n",
    "            X = test_scaled[i, 0:-1]\n",
    "            # invert scaling\n",
    "            yhat = invert_scale(scaler, X, yhat)\n",
    "            # invert differencing\n",
    "            yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "            # store forecast\n",
    "            predictions.append(yhat)\n",
    "        # report performance\n",
    "        rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "        print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "        error_scores.append(rmse)\n",
    "    return error_scores\n",
    " \n",
    "# configure the experiment\n",
    "# def run():\n",
    "# load dataset\n",
    "series = read_csv('sales-of-shampoo-over-a-three-ye.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# configure the experiment\n",
    "n_lag = 1\n",
    "n_repeats = 30\n",
    "n_epochs = 1000\n",
    "n_batch = 4\n",
    "n_neurons = 3\n",
    "regularizers = [L1L2(l1=0.0, l2=0.0), L1L2(l1=0.01, l2=0.0), L1L2(l1=0.0, l2=0.01), L1L2(l1=0.01, l2=0.01)]\n",
    "# run the experiment\n",
    "results = DataFrame()\n",
    "for reg in regularizers:\n",
    "    name = ('l1 %.2f,l2 %.2f' % (reg.l1, reg.l2))\n",
    "    results[name] = experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons, reg)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('experiment_reg_input.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Test RMSE: 93.885\n"
     ]
    }
   ],
   "source": [
    "def fit_lstm(train, n_batch, nb_epoch, n_neurons, reg):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True, recurrent_regularizer=reg))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    " \n",
    "# run a repeated experiment\n",
    "def experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons, reg):\n",
    "    # transform data to be stationary\n",
    "    raw_values = series.values\n",
    "    diff_values = difference(raw_values, 1)\n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised(diff_values, n_lag)\n",
    "    supervised_values = supervised.values[n_lag:,:]\n",
    "    # split data into train and test-sets\n",
    "    train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "    # run experiment\n",
    "    error_scores = list()\n",
    "    for r in range(n_repeats):\n",
    "        # fit the model\n",
    "        train_trimmed = train_scaled[2:, :]\n",
    "        lstm_model = fit_lstm(train_trimmed, n_batch, n_epochs, n_neurons, reg)\n",
    "        # forecast test dataset\n",
    "        test_reshaped = test_scaled[:,0:-1]\n",
    "        test_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "        output = lstm_model.predict(test_reshaped, batch_size=n_batch)\n",
    "        predictions = list()\n",
    "        for i in range(len(output)):\n",
    "            yhat = output[i,0]\n",
    "            X = test_scaled[i, 0:-1]\n",
    "            # invert scaling\n",
    "            yhat = invert_scale(scaler, X, yhat)\n",
    "            # invert differencing\n",
    "            yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "            # store forecast\n",
    "            predictions.append(yhat)\n",
    "        # report performance\n",
    "        rmse = sqrt(mean_squared_error(raw_values[-12:], predictions))\n",
    "        print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "        error_scores.append(rmse)\n",
    "    return error_scores\n",
    " \n",
    "# configure the experiment\n",
    "# def run():\n",
    "# load dataset\n",
    "series = read_csv('sales-of-shampoo-over-a-three-ye.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# configure the experiment\n",
    "n_lag = 1\n",
    "n_repeats = 30\n",
    "n_epochs = 1000\n",
    "n_batch = 4\n",
    "n_neurons = 3\n",
    "regularizers = [L1L2(l1=0.0, l2=0.0), L1L2(l1=0.01, l2=0.0), L1L2(l1=0.0, l2=0.01), L1L2(l1=0.01, l2=0.01)]\n",
    "# run the experiment\n",
    "results = DataFrame()\n",
    "for reg in regularizers:\n",
    "    name = ('l1 %.2f,l2 %.2f' % (reg.l1, reg.l2))\n",
    "    results[name] = experiment(series, n_lag, n_repeats, n_epochs, n_batch, n_neurons, reg)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('experiment_reg_recurrent.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
